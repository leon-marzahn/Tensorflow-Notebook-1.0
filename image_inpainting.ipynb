{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Image inpainting\n",
    "Based on [this paper](http://iizuka.cs.tsukuba.ac.jp/projects/completion/data/completion_sig2017.pdf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import dependencies"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "modern-diving",
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [],
   "source": [
    "checkpoint_path = 'checkpoints/image_inpainting/image_inpainting.ckpt'\n",
    "\n",
    "tqdm_callback = tfa.callbacks.TQDMProgressBar(\n",
    "  show_epoch_progress=False\n",
    ")\n",
    "\n",
    "def conv2d_relu(filters, kernel, **kwargs):\n",
    "  return [\n",
    "    keras.layers.Conv2D(filters, kernel, **kwargs),\n",
    "    keras.layers.ReLU()\n",
    "  ]\n",
    "\n",
    "def deconv2d_relu(filters, kernel, **kwargs):\n",
    "  return [\n",
    "    keras.layers.Conv2DTranspose(filters, kernel, **kwargs),\n",
    "    keras.layers.ReLU()\n",
    "  ]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% code\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generator model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "vanilla-michigan",
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_633 (Conv2D)          (None, 1024, 1024, 64)    4864      \n",
      "_________________________________________________________________\n",
      "re_lu_64 (ReLU)              (None, 1024, 1024, 64)    0         \n",
      "_________________________________________________________________\n",
      "downscale_1 (Conv2D)         (None, 512, 512, 128)     73856     \n",
      "_________________________________________________________________\n",
      "re_lu_65 (ReLU)              (None, 512, 512, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_634 (Conv2D)          (None, 512, 512, 128)     147584    \n",
      "_________________________________________________________________\n",
      "re_lu_66 (ReLU)              (None, 512, 512, 128)     0         \n",
      "_________________________________________________________________\n",
      "downscale_2 (Conv2D)         (None, 256, 256, 256)     295168    \n",
      "_________________________________________________________________\n",
      "re_lu_67 (ReLU)              (None, 256, 256, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_635 (Conv2D)          (None, 256, 256, 256)     590080    \n",
      "_________________________________________________________________\n",
      "re_lu_68 (ReLU)              (None, 256, 256, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_636 (Conv2D)          (None, 256, 256, 256)     590080    \n",
      "_________________________________________________________________\n",
      "re_lu_69 (ReLU)              (None, 256, 256, 256)     0         \n",
      "_________________________________________________________________\n",
      "dilate_1 (Conv2D)            (None, 256, 256, 256)     590080    \n",
      "_________________________________________________________________\n",
      "re_lu_70 (ReLU)              (None, 256, 256, 256)     0         \n",
      "_________________________________________________________________\n",
      "dilate_2 (Conv2D)            (None, 256, 256, 256)     590080    \n",
      "_________________________________________________________________\n",
      "re_lu_71 (ReLU)              (None, 256, 256, 256)     0         \n",
      "_________________________________________________________________\n",
      "dilate_3 (Conv2D)            (None, 256, 256, 256)     590080    \n",
      "_________________________________________________________________\n",
      "re_lu_72 (ReLU)              (None, 256, 256, 256)     0         \n",
      "_________________________________________________________________\n",
      "dilate_4 (Conv2D)            (None, 256, 256, 256)     590080    \n",
      "_________________________________________________________________\n",
      "re_lu_73 (ReLU)              (None, 256, 256, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_637 (Conv2D)          (None, 256, 256, 256)     590080    \n",
      "_________________________________________________________________\n",
      "re_lu_74 (ReLU)              (None, 256, 256, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_638 (Conv2D)          (None, 256, 256, 256)     590080    \n",
      "_________________________________________________________________\n",
      "re_lu_75 (ReLU)              (None, 256, 256, 256)     0         \n",
      "_________________________________________________________________\n",
      "upscale_1 (Conv2DTranspose)  (None, 512, 512, 128)     524416    \n",
      "_________________________________________________________________\n",
      "re_lu_76 (ReLU)              (None, 512, 512, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_639 (Conv2D)          (None, 512, 512, 128)     147584    \n",
      "_________________________________________________________________\n",
      "re_lu_77 (ReLU)              (None, 512, 512, 128)     0         \n",
      "_________________________________________________________________\n",
      "upscale_2 (Conv2DTranspose)  (None, 1026, 1026, 64)    131136    \n",
      "_________________________________________________________________\n",
      "re_lu_78 (ReLU)              (None, 1026, 1026, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_640 (Conv2D)          (None, 1026, 1026, 32)    18464     \n",
      "_________________________________________________________________\n",
      "re_lu_79 (ReLU)              (None, 1026, 1026, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_641 (Conv2D)          (None, 1024, 1024, 3)     867       \n",
      "=================================================================\n",
      "Total params: 6,064,579\n",
      "Trainable params: 6,064,579\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator_layers = list(plt.cbook.flatten([\n",
    "  keras.layers.Input(shape=(1024, 1024, 3)),\n",
    "  conv2d_relu(64, (5, 5), padding='same'),\n",
    "\n",
    "  conv2d_relu(128, (3, 3), strides=(2, 2), padding='same', name='downscale_1'),\n",
    "  conv2d_relu(128, (3, 3), padding='same'),\n",
    "\n",
    "  conv2d_relu(256, (3, 3), strides=(2, 2), padding='same', name='downscale_2'),\n",
    "  conv2d_relu(256, (3, 3), padding='same'),\n",
    "  conv2d_relu(256, (3, 3), padding='same'),\n",
    "  conv2d_relu(256, (3, 3), dilation_rate=2, padding='same', name='dilate_1'),\n",
    "  conv2d_relu(256, (3, 3), dilation_rate=4, padding='same', name='dilate_2'),\n",
    "  conv2d_relu(256, (3, 3), dilation_rate=8, padding='same', name='dilate_3'),\n",
    "  conv2d_relu(256, (3, 3), dilation_rate=16, padding='same', name='dilate_4'),\n",
    "  conv2d_relu(256, (3, 3), padding='same'),\n",
    "  conv2d_relu(256, (3, 3), padding='same'),\n",
    "\n",
    "  deconv2d_relu(128, (4, 4), strides=(2, 2), padding='same', name='upscale_1'),\n",
    "  conv2d_relu(128, (3, 3), padding='same'),\n",
    "\n",
    "  deconv2d_relu(64, (4, 4), strides=(2, 2), name='upscale_2'),\n",
    "  conv2d_relu(32, (3, 3), padding='same'),\n",
    "  keras.layers.Conv2D(3, (3, 3), activation=keras.activations.sigmoid)\n",
    "]))\n",
    "generator_model = keras.Sequential(layers=generator_layers, name='generator')\n",
    "generator_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Local discriminator model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"local_discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_657 (Conv2D)          (None, 64, 64, 64)        4864      \n",
      "_________________________________________________________________\n",
      "re_lu_91 (ReLU)              (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_658 (Conv2D)          (None, 32, 32, 128)       204928    \n",
      "_________________________________________________________________\n",
      "re_lu_92 (ReLU)              (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_659 (Conv2D)          (None, 16, 16, 256)       819456    \n",
      "_________________________________________________________________\n",
      "re_lu_93 (ReLU)              (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_660 (Conv2D)          (None, 8, 8, 512)         3277312   \n",
      "_________________________________________________________________\n",
      "re_lu_94 (ReLU)              (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_661 (Conv2D)          (None, 4, 4, 512)         6554112   \n",
      "_________________________________________________________________\n",
      "re_lu_95 (ReLU)              (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 4, 4, 1024)        525312    \n",
      "=================================================================\n",
      "Total params: 11,385,984\n",
      "Trainable params: 11,385,984\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "local_discriminator_layers = list(plt.cbook.flatten([\n",
    "  keras.layers.Input(shape=(128, 128, 3)),\n",
    "  conv2d_relu(64, (5, 5), strides=(2, 2), padding='same'),\n",
    "  conv2d_relu(128, (5, 5), strides=(2, 2), padding='same'),\n",
    "  conv2d_relu(256, (5, 5), strides=(2, 2), padding='same'),\n",
    "  conv2d_relu(512, (5, 5), strides=(2, 2), padding='same'),\n",
    "  conv2d_relu(512, (5, 5), strides=(2, 2), padding='same'),\n",
    "\n",
    "  keras.layers.Dense(units=1024)\n",
    "]))\n",
    "local_discriminator_model = keras.Sequential(layers=local_discriminator_layers, name='local_discriminator')\n",
    "local_discriminator_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% code\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Concatenation layer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [],
   "source": [
    "def concatenate_discriminator_values(x, y):\n",
    "  return keras.layers.Dense(units=1, activation=keras.activations.sigmoid)(keras.layers.Concatenate([x, y]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% code\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Early testing of the generator"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x2a13639b640>"
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "early_test_noise = tf.random.normal((1024, 1024, 3))\n",
    "early_test_noise_tensor = tf.reshape(early_test_noise, (1, 1024, 1024, 3))\n",
    "\n",
    "generated = generator_model(early_test_noise_tensor, training=False)\n",
    "plt.imshow(generated[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% code\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generator loss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "  return keras.losses.BinaryCrossentropy(from_logits=True)(tf.ones_like(fake_output), fake_output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% code\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Discriminator loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "  cross_entropy = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "  real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "  fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "  return real_loss + fake_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% code\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "  noise = tf.random.normal((16, 1024, 1024, 3))\n",
    "\n",
    "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "    generated_images = generator_model(noise, training=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% code\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}